{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtlIRiNXWlQ0"
      },
      "source": [
        "# Waste identification with instance segmentation in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohoMgYgXWsIO"
      },
      "source": [
        "Welcome to the Instance Segmentation Colab! This notebook will take you through the steps of running an \"out-of-the-box\" Mask RCNN Instance Segmentation model on images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PKG9z4VYPEs"
      },
      "source": [
        "To finish this task, a proper path for the saved models and a single image needs to be provided. The path to the labels on which the models are trained is in the waste_identification_ml directory inside the Tensorflow Model Garden repository. The label files are inferred automatically for both models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7yl9CqgYWvS"
      },
      "source": [
        "## Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELUFMVDDAopS"
      },
      "outputs": [],
      "source": [
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import logging\n",
        "import pandas as pd\n",
        "from labels import load_labels\n",
        "\n",
        "logging.disable(logging.WARNING)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imIpwZgv_3dE"
      },
      "source": [
        "Run the following cell to import utility functions that will be needed for pre-processing, post-processing and color detection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_77YK3a_BCg_"
      },
      "source": [
        "To visualize the images with the proper detected boxes and segmentation masks, we will use the TensorFlow Object Detection API. To install it we will clone the repo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCC-WANYBD03",
        "outputId": "f507a381-aa79-4a45-c722-4109e252ef71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3985, done.\u001b[K\n",
            "remote: Counting objects: 100% (3985/3985), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3093/3093), done.\u001b[K\n",
            "remote: Total 3985 (delta 1151), reused 1942 (delta 835), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3985/3985), 49.76 MiB | 33.28 MiB/s, done.\n",
            "Resolving deltas: 100% (1151/1151), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the tensorflow models repository\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1dYyG55BtWb"
      },
      "outputs": [],
      "source": [
        "sys.path.append('models/research/')\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq2DNpXQ_0-n"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO488S78_2GJ"
      },
      "outputs": [],
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (1, h, w, 3)\n",
        "  \"\"\"\n",
        "  image = None\n",
        "  if(path.startswith('http')):\n",
        "    response = urlopen(path)\n",
        "    image_data = response.read()\n",
        "    image_data = BytesIO(image_data)\n",
        "    image = Image.open(image_data)\n",
        "  else:\n",
        "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(image_data))\n",
        "\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (1, im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "def load_model(model_handle):\n",
        "    \"\"\"Loads a TensorFlow SavedModel and returns a function that can be used to make predictions.\n",
        "\n",
        "    Args:\n",
        "      model_handle: A path to a TensorFlow SavedModel.\n",
        "\n",
        "    Returns:\n",
        "      A function that can be used to make predictions.\n",
        "    \"\"\"\n",
        "    print('loading model...')\n",
        "    print(model_handle)\n",
        "    model = tf.saved_model.load(model_handle)\n",
        "    print('model loaded!')\n",
        "    detection_fn = model.signatures['serving_default']\n",
        "    return detection_fn\n",
        "\n",
        "\n",
        "def perform_detection(model, image):\n",
        "  \"\"\"Performs Mask RCNN on an image using the specified model.\n",
        "\n",
        "  Args:\n",
        "    model: A function that can be used to make predictions.\n",
        "    image_np: A NumPy array representing the image to be detected.\n",
        "\n",
        "  Returns:\n",
        "    A list of detections.\n",
        "  \"\"\"\n",
        "  detection_fn = model(image)\n",
        "  detection_fn = {key: value.numpy() for key, value in detection_fn.items()}\n",
        "  return detection_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7d00cJH-68Z"
      },
      "outputs": [],
      "source": [
        "# 'material_model' output is both material and its sub type e.g. Plastics_PET\n",
        "# 'material_form_model' outputs the form of an object e.g. can, bottle, etc\n",
        "MODEL_WEIGHTS = {\n",
        "'material_url' : 'https://storage.googleapis.com/tf_model_garden/vision/waste_identification_ml/two_model_strategy/material/material_version_1.zip',\n",
        "'material_form_url' : 'https://storage.googleapis.com/tf_model_garden/vision/waste_identification_ml/two_model_strategy/material_form/material_form_version_1.zip',\n",
        "}\n",
        "\n",
        "ALL_MODELS = {\n",
        "'material_model' : 'material/two_model_material_1_saved/saved_model/',\n",
        "'material_form_model' : 'material_form/two_model_material_form_1_saved/saved_model/',\n",
        "}\n",
        "\n",
        "LABELS = {\n",
        "'material_model' : 'models/official/projects/waste_identification_ml/pre_processing/config/data/two_model_strategy_material.csv',\n",
        "'material_form_model' : 'models/official/projects/waste_identification_ml/pre_processing/config/data/two_model_strategy_material_form.csv',\n",
        "}\n",
        "\n",
        "# path to a sample image stored in the repo\n",
        "IMAGES_FOR_TEST = {\n",
        "  'Image1' : 'models/official/projects/waste_identification_ml/pre_processing/config/sample_images/image_2.png'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XjfDEq--UlE"
      },
      "source": [
        "## Import pre-trained models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUmc3aMXWjUO"
      },
      "outputs": [],
      "source": [
        "# download the model weights from the Google's repo\n",
        "url1 = MODEL_WEIGHTS['material_url']\n",
        "url2 = MODEL_WEIGHTS['material_form_url']\n",
        "!python download_and_unzip_models.py --material_url $url1 material_form_url $url2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6mmyLsOJicF"
      },
      "source": [
        "## Load label map data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM2A29OrJqaU"
      },
      "source": [
        "Label maps correspond index numbers to category names, so that when our convolution network predicts 5, we know that this corresponds to airplane. Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine.\n",
        "\n",
        "We are going, for simplicity, to load from the repository that we loaded the Object Detection API code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RUzrh0uegqt"
      },
      "outputs": [],
      "source": [
        "# the total number of predicted labels (category_indices) for a combined model = 741\n",
        "category_indices, category_index = load_labels(LABELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBm2aQzfHhId",
        "outputId": "37527599-2060-4167-f7dd-74649a07a58f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Na',\n",
              " 'Fiber_Na',\n",
              " 'Food_Na',\n",
              " 'Glass_Na',\n",
              " 'Inorganic-wastes_Na',\n",
              " 'Metals_Na',\n",
              " 'Plastics_HDPE',\n",
              " 'Plastics_LDPE',\n",
              " 'Plastics_Others-HIPC',\n",
              " 'Plastics_Others-MLP',\n",
              " 'Plastics_Others-Tetrapak',\n",
              " 'Plastics_PET',\n",
              " 'Plastics_PP',\n",
              " 'Plastics_PS',\n",
              " 'Plastics_PVC',\n",
              " 'Rubber-\u0026-Leather_Na',\n",
              " 'Textiles_Na',\n",
              " 'Wood_Na',\n",
              " 'Yard-trimming_Na']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display labels only for 'material' model\n",
        "# total number of labels for 'material' model = 19\n",
        "category_indices[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh_Ey6lXHs8m",
        "outputId": "b53520a4-e18c-4f40-d2a9-6b49348c251d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Na',\n",
              " 'Bag',\n",
              " 'Battery',\n",
              " 'Blister-pack',\n",
              " 'Book-\u0026-magazine',\n",
              " 'Bottle',\n",
              " 'Box',\n",
              " 'Brush',\n",
              " 'Bulb',\n",
              " 'Can',\n",
              " 'Cards',\n",
              " 'Carton',\n",
              " 'Cassette-\u0026-tape',\n",
              " 'Clamshell',\n",
              " 'Clothes',\n",
              " 'Container',\n",
              " 'Cosmetic',\n",
              " 'Cup-\u0026-glass',\n",
              " 'Cutlery',\n",
              " 'Electronic-devices',\n",
              " 'Flexibles',\n",
              " 'Foil',\n",
              " 'Foot-wear',\n",
              " 'Hangers',\n",
              " 'Jug-\u0026-Jar',\n",
              " 'Lid',\n",
              " 'Mirror',\n",
              " 'Office-Stationary',\n",
              " 'Paper-Products-Others',\n",
              " 'Paper-Products-Others-Cardboard',\n",
              " 'Paper-Products-Others-Newspaper',\n",
              " 'Paper-Products-Others-Whitepaper',\n",
              " 'Pipe',\n",
              " 'Sachets-\u0026-Pouch',\n",
              " 'Scissor',\n",
              " 'Tangler',\n",
              " 'Toys',\n",
              " 'Tray',\n",
              " 'Tube']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display labels only for 'material_form' model\n",
        "# total number of labels for 'material form' model = 39\n",
        "category_indices[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFczkMGBClZ4"
      },
      "source": [
        "## Load pre-trained weights for both models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J6MgjOSC5JO",
        "outputId": "3de66985-bdb1-428d-85e1-5be4317d6bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading model...\n",
            "material/two_model_material_1_saved/saved_model/\n",
            "model loaded!\n",
            "loading model...\n",
            "material_form/two_model_material_form_1_saved/saved_model/\n",
            "model loaded!\n"
          ]
        }
      ],
      "source": [
        "# loading both models\n",
        "detection_fns = [load_model(model_path) for model_path in ALL_MODELS.values()]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
