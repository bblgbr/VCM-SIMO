# ViT video classification on Kinetics-400.
#
# --experiment_type=mh_video_classification_strong_aug
runtime:
  distribution_strategy: 'tpu'
  mixed_precision_dtype: 'bfloat16'
task:
  init_checkpoint: '/tmp/video_mae/VIT_B_16x4_MAE_PT.npy'
  init_checkpoint_modules: 'customized_vmae'
  model:
    backbone:
      type: 'vit_3d'
      vit_3d:
        variant: 'mae'
        pooler: 'none'
        model_name: 'vit-b16'
        temporal_patch_size: 2
        representation_size: 0
        init_stochastic_depth_rate: 0.2
        pos_embed_shape:
        - 8  # time
        - 196  # space
        transformer:
          dropout_rate: 0.0
    classifier_type: 'pooler'
    dropout_rate: 0.5
    norm_activation:
      norm_momentum: 0.9
      use_sync_bn: true
  train_data:
    name: kinetics400
    num_classes: 400
    num_examples: 235693
    zero_centering_image: false
    feature_shape: !!python/tuple
    - 16
    - 224
    - 224
    - 3
    temporal_stride: 4
    global_batch_size: 256
    dtype: 'bfloat16'
    shuffle_buffer_size: 512
    prefetch_buffer_size: 512
    drop_remainder: true
  validation_data:
    name: kinetics400
    num_classes: 400
    zero_centering_image: false
    global_batch_size: 16
    feature_shape: !!python/tuple
    - 16
    - 224
    - 224
    - 3
    temporal_stride: 4
    num_test_clips: 4
    num_test_crops: 3
    dtype: 'bfloat16'
    drop_remainder: true
  losses:
    label_smoothing: 0.1
trainer:
  optimizer_config:
    learning_rate:
      cosine:
        initial_learning_rate: 1e-4
        decay_steps: 138101  # 138k
    warmup:
      linear:
        warmup_steps: 4600
    optimizer:
      type: 'adamw'
      adamw:
        beta_1: 0.9
        beta_2: 0.999
        amsgrad: false
        weight_decay_rate: 1e-5
        exclude_from_weight_decay: !!python/list
        - 'LayerNorm'
        - 'layer_norm'
        - 'bias'
  train_steps: 138101  # 138k, 150 eps
  validation_steps: 1196
  steps_per_loop: 1000
  summary_interval: 1000
  validation_interval: 1000
