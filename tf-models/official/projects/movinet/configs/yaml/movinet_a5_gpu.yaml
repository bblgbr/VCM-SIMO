# Video classification using MoViNet-A5 backbone on multiple GPUs.
# This configuration is incomplete - Some parameters will be set by model garden Docker.
# --experiment_type=movinet_kinetics600

runtime:
  distribution_strategy: 'multi_worker_mirrored'
  mixed_precision_dtype: 'bfloat16'
task:
  losses:
    l2_weight_decay: 0.00003
    label_smoothing: 0.1
  model:
    backbone:
      movinet:
        model_id: 'a5'
        stochastic_depth_drop_rate: 0.2
        causal: false
    norm_activation:
      use_sync_bn: true
    dropout_rate: 0.5
    activation: 'swish'
  train_data:
    variant_name: rgb
    feature_shape: !!python/tuple
    - 32
    - 320
    - 320
    - 3
    temporal_stride: 2
    random_stride_range: 1
    dtype: 'bfloat16'
    min_image_size: 368
    aug_max_area_ratio: 1.0
    aug_max_aspect_ratio: 2.0
    aug_min_area_ratio: 0.08
    aug_min_aspect_ratio: 0.5
  validation_data:
    feature_shape: !!python/tuple
    - 32
    - 320
    - 320
    - 3
    temporal_stride: 2
    num_test_clips: 1
    num_test_crops: 1
    min_image_size: 368
    dtype: 'bfloat16'
    drop_remainder: false
trainer:
  optimizer_config:
    learning_rate:
      cosine:
        initial_learning_rate: 1.8
        decay_steps: 85785
    warmup:
      linear:
        warmup_steps: 300
    optimizer:
      type: 'rmsprop'
      rmsprop:
        rho: 0.9
        momentum: 0.9
        epsilon: 1.0
        clipnorm: 1.0
  steps_per_loop: 500
  summary_interval: 500
  validation_interval: 500
